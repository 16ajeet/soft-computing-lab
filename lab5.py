# 16. Write a Python program for Kohonen’s Self-Organizing Map (SOM). Input neurons=5, output
# neurons=2. Learning rate=0.1. Use Squared Euclidean distance.
# 17. Write a Python program to implement a Full Counterpropagation Network (CPN). The network
# should consist of 4 input neurons, 2 neurons in the hidden (Kohonen) layer, and 2 neurons in
# the output (Grossberg) layer. Use all initial learning rates as 0.5 and the Squared Euclidean
# distance as the similarity measure to determine the winning neuron in the Kohonen layer. The
# program should perform both Phase I (unsupervised learning) and Phase II (supervised
# learning) of the CPN algorithm. Use the following input and target pairs for training: X =
# {(1,0,0,0), (0,1,0,0), (0,0,1,0), (0,0,0,1)} and corresponding targets Y = {(1,0), (0,1), (1,0),
# (0,1)}. Display the initial weights of both layers, identify the winning neuron for each input
# during Phase I, update and display the weights after both training phases, and finally, show the
# output generated by the network for each input pattern.
# 18. Write a Python Program to implement ART1 and ART 2.

import numpy as np

# ==========================================================
# Common helper: Squared Euclidean distance
# ==========================================================
def euclid_sq(x, w):
    return np.sum((x - w) ** 2)

# ==========================================================
# 16. Kohonen’s Self-Organizing Map (SOM)
#    - Input neurons = 5
#    - Output neurons = 2
#    - Learning rate = 0.1
#    - Squared Euclidean distance
# ==========================================================
def train_som(X, n_outputs=2, lr=0.1, epochs=10, seed=0):
    """
    X: (n_samples, 5)
    n_outputs: number of Kohonen neurons (2)
    """
    rng = np.random.default_rng(seed)
    n_samples, n_features = X.shape

    # Initialize weights: 2 x 5
    W = rng.random((n_outputs, n_features))

    for epoch in range(epochs):
        print(f"\n[SOM] Epoch {epoch+1}")
        for x in X:
            # Squared Euclidean distance to each output neuron
            dists = np.array([euclid_sq(x, w) for w in W])
            winner = int(np.argmin(dists))

            # Update winner neuron
            W[winner] += lr * (x - W[winner])

    return W

# ==========================================================
# 17. Full Counterpropagation Network (CPN)
#    - 4 input neurons
#    - 2 Kohonen neurons (hidden)
#    - 2 Grossberg neurons (output)
#    - lr_kohonen = lr_grossberg = 0.5
#    - Squared Euclidean distance for winner in Kohonen
# ==========================================================
def train_cpn(X, Y, n_hidden=2, lr_k=0.5, lr_g=0.5, seed=0,
              epochs_phase1=1, epochs_phase2=1):
    """
    X: (n_samples, 4)
    Y: (n_samples, 2)
    Returns:
        W_k : Kohonen weights (2 x 4)
        W_g : Grossberg weights (2 x 2)
    """
    X = np.array(X, dtype=float)
    Y = np.array(Y, dtype=float)
    n_samples, n_inputs = X.shape
    n_outputs = Y.shape[1]

    rng = np.random.default_rng(seed)

    # Initial weights
    W_k = rng.random((n_hidden, n_inputs)) * 0.1    # 2x4
    W_g = rng.random((n_outputs, n_hidden)) * 0.1   # 2x2

    print("Initial Kohonen weights:\n", W_k)
    print("Initial Grossberg weights:\n", W_g)

    # ---------- Phase I: Unsupervised learning (Kohonen layer) ----------
    print("\n=== Phase I: Unsupervised learning (Kohonen layer) ===")
    for epoch in range(epochs_phase1):
        print(f"\n[Phase I] Epoch {epoch+1}")
        for x in X:
            dists = np.array([euclid_sq(x, w) for w in W_k])
            winner = int(np.argmin(dists))
            print(f"Input {x} -> winner neuron: {winner}")
            # Update winner neuron
            W_k[winner] += lr_k * (x - W_k[winner])

    print("\nKohonen weights after Phase I:\n", W_k)

    # ---------- Phase II: Supervised learning (Grossberg layer) ----------
    print("\n=== Phase II: Supervised learning (Grossberg layer) ===")
    for epoch in range(epochs_phase2):
        print(f"\n[Phase II] Epoch {epoch+1}")
        for x, y in zip(X, Y):
            dists = np.array([euclid_sq(x, w) for w in W_k])
            winner = int(np.argmin(dists))

            # Kohonen output (one-hot)
            h = np.zeros(n_hidden)
            h[winner] = 1

            # Grossberg output
            o = W_g @ h

            # Error
            e = y - o

            # Grossberg weight update
            W_g += lr_g * np.outer(e, h)

            print(f"Input {x}, target {y}, winner {winner}, output before update {o}")

    print("\nFinal Kohonen weights:\n", W_k)
    print("Final Grossberg weights:\n", W_g)

    return W_k, W_g


def cpn_predict(X, W_k, W_g):
    X = np.array(X, dtype=float)
    n_hidden = W_k.shape[0]
    outputs = []
    for x in X:
        dists = np.array([euclid_sq(x, w) for w in W_k])
        winner = int(np.argmin(dists))
        h = np.zeros(n_hidden)
        h[winner] = 1
        o = W_g @ h
        outputs.append(o)
    return np.array(outputs)

# ==========================================================
# 18. ART1 (binary) and ART2 (continuous) - simple versions
# ==========================================================
def art1_train(X, vigilance=0.8, n_cat=5):
    """
    Simple ART1 for binary patterns.
    - X: (n_samples, n_features), values in {0,1}
    - vigilance in [0,1]
    Returns:
        W : category templates (n_cat, n_features)
        assignments : category index for each pattern
    """
    X = np.array(X, dtype=float)
    n_samples, n_features = X.shape

    # Start with all-ones templates (max general category)
    W = np.ones((n_cat, n_features))
    assignments = []

    for x in X:
        if np.sum(x) == 0:
            # trivial pattern
            assignments.append(0)
            continue

        # Similarity: |x ∧ W_j|
        sim = np.array([np.sum(np.minimum(x, W[j])) for j in range(n_cat)])
        order = np.argsort(-sim)  # try best matching first
        chosen = None

        for j in order:
            rho = sim[j] / (np.sum(x) + 1e-12)  # match / |x|
            if rho >= vigilance:
                # Learning: intersection
                W[j] = np.minimum(W[j], x)
                chosen = j
                break

        # If no category passes vigilance, force best one
        if chosen is None:
            j = order[0]
            W[j] = np.minimum(W[j], x)
            chosen = j

        assignments.append(chosen)

    return W, assignments


def art2_train(X, vigilance=0.8, n_cat=5):
    """
    Very simplified ART2-like clustering for continuous inputs in [0,1].
    Not a full textbook ART2, but enough for basic lab demonstration.
    - Uses cosine similarity and a vigilance threshold.
    """
    X = np.array(X, dtype=float)
    n_samples, n_features = X.shape

    rng = np.random.default_rng(0)
    # Random templates in [0,1]
    W = rng.random((n_cat, n_features))
    assignments = []

    for x in X:
        # Normalize input
        norm_x = np.linalg.norm(x) + 1e-12
        x_n = x / norm_x

        # Cosine similarity with each category
        sim = []
        for j in range(n_cat):
            wj = W[j]
            sim.append(np.dot(x_n, wj / (np.linalg.norm(wj) + 1e-12)))
        sim = np.array(sim)

        order = np.argsort(-sim)
        chosen = None

        for j in order:
            rho = sim[j]        # already in [-1,1]
            if rho >= vigilance:
                # Move template toward x_n
                W[j] = 0.5 * W[j] + 0.5 * x_n
                chosen = j
                break

        if chosen is None:
            j = order[0]
            W[j] = 0.5 * W[j] + 0.5 * x_n
            chosen = j

        assignments.append(chosen)

    return W, assignments

# ==========================================================
# Demo / quick test (you can keep this or remove for submission)
# ==========================================================
if __name__ == "__main__":
    rng = np.random.default_rng(0)

    # ---------- SOM demo ----------
    X_som = rng.random((10, 5))  # 10 samples, 5 features (input neurons)
    W_som = train_som(X_som, n_outputs=2, lr=0.1, epochs=10)
    print("\nFinal SOM weights:\n", W_som)

    # ---------- CPN demo ----------
    X = np.array([
        [1,0,0,0],
        [0,1,0,0],
        [0,0,1,0],
        [0,0,0,1]
    ], dtype=float)

    Y = np.array([
        [1,0],
        [0,1],
        [1,0],
        [0,1]
    ], dtype=float)

    W_k, W_g = train_cpn(X, Y, n_hidden=2, lr_k=0.5, lr_g=0.5)

    print("\nCPN final outputs:")
    outputs = cpn_predict(X, W_k, W_g)
    for x, y, o in zip(X, Y, outputs):
        print(f"Input: {x}, Target: {y}, Output: {o}")

    # ---------- ART1 & ART2 demo ----------
    Xb = np.array([
        [1,0,0],
        [0,1,0],
        [1,1,0],
        [0,0,1]
    ], dtype=float)

    W1, assign1 = art1_train(Xb, vigilance=0.8, n_cat=3)
    print("\nART1 templates:\n", W1)
    print("ART1 assignments:", assign1)

    W2, assign2 = art2_train(Xb, vigilance=0.5, n_cat=3)
    print("\nART2 templates:\n", W2)
    print("ART2 assignments:", assign2)
